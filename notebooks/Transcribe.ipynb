{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# local-transcribe Â· Main Notebook\n",
    "\n",
    "This notebook runs **offline** transcription using models cached in `./models/`.\n",
    "\n",
    "It supports two modes:\n",
    "- **Dual-track**: clean merge from interviewer + participant files (no diarization)\n",
    "- **Combined**: single mixed audio (ASR + diarization)\n",
    "\n",
    "Run cells top-to-bottom. If anything fails, check the **Setup & Checks** cell first."
   ]
  },
  {
   "cell_type": "code",
   "metadata": { "tags": ["parameters"] },
   "source": [
    "# === Parameters (edit these) ===\n",
    "MODE = \"dual\"  # 'dual' or 'combined'\n",
    "ASR_MODEL = \"medium.en\"  # 'medium.en' or 'large-v3-turbo'\n",
    "\n",
    "# Absolute paths strongly recommended\n",
    "INTERVIEWER_PATH = \"/absolute/path/to/interviewer.m4a\"  # used if MODE='dual'\n",
    "PARTICIPANT_PATH = \"/absolute/path/to/participant.m4a\"  # used if MODE='dual'\n",
    "\n",
    "COMBINED_PATH = \"/absolute/path/to/mixed.m4a\"           # used if MODE='combined'\n",
    "\n",
    "# Where outputs go (will be created if missing)\n",
    "OUTPUT_DIR = \"/absolute/path/to/output/session_folder\"\n",
    "\n",
    "# Export options\n",
    "WRITE_VTT = False\n",
    "RENDER_BLACK = False  # burn subtitles to a black video (requires ffmpeg)\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": { "tags": ["setup"] },
   "source": [
    "# === Setup & Checks ===\n",
    "import os, sys, pathlib\n",
    "repo_root = pathlib.Path.cwd().resolve().parent if (pathlib.Path.cwd().name == \"notebooks\") else pathlib.Path.cwd().resolve()\n",
    "sys.path.append(str(repo_root / \"src\"))\n",
    "\n",
    "# Force offline for runtime (models must already exist in ./models)\n",
    "os.environ.setdefault(\"HF_HOME\", str(repo_root / \"models\"))\n",
    "os.environ.setdefault(\"TRANSFORMERS_CACHE\", str(repo_root / \"models\"))\n",
    "os.environ.setdefault(\"PYANNOTE_CACHE\", str(repo_root / \"models\" / \"diarization\"))\n", 
    "os.environ.setdefault(\"XDG_CACHE_HOME\", str(repo_root / \"models\" / \".xdg\"))\n",
    "os.environ.setdefault(\"HF_HUB_OFFLINE\", \"1\")\n",
    "\n",
    "models_dir = repo_root / \"models\"\n",
    "assert models_dir.exists(), \"models/ not found. Run scripts/download_models.py first.\"\n",
    "\n",
    "print(\"Repo root:\", repo_root)\n",
    "print(\"Models dir:\", models_dir)\n",
    "print(\"MODE:\", MODE, \"ASR_MODEL:\", ASR_MODEL)\n",
    "print(\"OUTPUT_DIR:\", OUTPUT_DIR)\n",
    "\n",
    "from session import ensure_session_dirs\n",
    "from audio_io import standardize_and_get_path\n",
    "from asr import transcribe_with_alignment\n",
    "from turns import build_turns\n",
    "from merge import merge_turn_streams\n",
    "from srt_vtt import write_srt, write_vtt\n",
    "from txt_writer import write_timestamped_txt, write_plain_txt\n",
    "from render_black import render_black_video\n",
    "from diarize import diarize_mixed\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": { "tags": ["validate-params"] },
   "source": [
    "# === Validate parameters & create session dirs ===\n",
    "out_paths = ensure_session_dirs(OUTPUT_DIR)\n",
    "print(\"Output paths:\", out_paths)\n",
    "\n",
    "if MODE not in (\"dual\", \"combined\"):\n",
    "    raise ValueError(\"MODE must be 'dual' or 'combined'\")\n",
    "if ASR_MODEL not in (\"medium.en\", \"large-v3-turbo\"):\n",
    "    raise ValueError(\"ASR_MODEL must be 'medium.en' or 'large-v3-turbo'\")\n",
    "\n",
    "if MODE == \"dual\":\n",
    "    if not (pathlib.Path(INTERVIEWER_PATH).exists() and pathlib.Path(PARTICIPANT_PATH).exists()):\n",
    "        raise FileNotFoundError(\"Dual mode requires valid INTERVIEWER_PATH and PARTICIPANT_PATH\")\n",
    "elif MODE == \"combined\":\n",
    "    if not pathlib.Path(COMBINED_PATH).exists():\n",
    "        raise FileNotFoundError(\"Combined mode requires valid COMBINED_PATH\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": { "tags": ["dual-track"] },
   "source": [
    "# === Dual-track pipeline (skip if MODE='combined') ===\n",
    "if MODE == \"dual\":\n",
    "    # 1) Standardize inputs (convert to WAV 16k mono on temp paths if needed)\n",
    "    std_int_path = standardize_and_get_path(INTERVIEWER_PATH)\n",
    "    std_part_path = standardize_and_get_path(PARTICIPANT_PATH)\n",
    "    \n",
    "    # 2) Transcribe + align per track\n",
    "    interviewer_words = transcribe_with_alignment(std_int_path, asr_model=ASR_MODEL, role=\"Interviewer\")\n",
    "    participant_words = transcribe_with_alignment(std_part_path, asr_model=ASR_MODEL, role=\"Participant\")\n",
    "\n",
    "    # 3) Build turns per track\n",
    "    interviewer_turns = build_turns(interviewer_words, speaker_label=\"Interviewer\")\n",
    "    participant_turns  = build_turns(participant_words,  speaker_label=\"Participant\")\n",
    "\n",
    "    # 4) Merge by time with overlap handling\n",
    "    merged_turns = merge_turn_streams(interviewer_turns, participant_turns)\n",
    "\n",
    "    # 5) Write per-speaker artifacts\n",
    "    write_timestamped_txt(interviewer_turns, out_paths[\"speaker_interviewer\"] / \"interviewer.timestamped.txt\")\n",
    "    write_plain_txt(interviewer_turns,        out_paths[\"speaker_interviewer\"] / \"interviewer.txt\")\n",
    "    write_timestamped_txt(participant_turns,  out_paths[\"speaker_participant\"] / \"participant.timestamped.txt\")\n", 
    "    write_plain_txt(participant_turns,        out_paths[\"speaker_participant\"] / \"participant.txt\")\n",
    "\n",
    "    # 6) Write merged artifacts\n",
    "    write_timestamped_txt(merged_turns, out_paths[\"merged\"] / \"transcript.timestamped.txt\")\n",
    "    write_plain_txt(merged_turns,       out_paths[\"merged\"] / \"transcript.txt\")\n",
    "    srt_path = out_paths[\"merged\"] / \"subtitles.srt\"\n",
    "    write_srt(merged_turns, srt_path)\n",
    "    if WRITE_VTT:\n",
    "        write_vtt(merged_turns, out_paths[\"merged\"] / \"subtitles.vtt\")\n",
    "    if RENDER_BLACK:\n",
    "        render_black_video(srt_path, out_paths[\"merged\"] / \"black_subtitled.mp4\", audio_path=std_int_path)  # you can swap audio_path\n",
    "\n",
    "    print(\"Dual-track processing complete.\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": { "tags": ["combined"] },
   "source": [
    "# === Combined (mixed) pipeline (skip if MODE='dual') ===\n",
    "if MODE == \"combined\":\n",
    "    # 1) Standardize input\n",
    "    std_mix_path = standardize_and_get_path(COMBINED_PATH)\n",
    "\n",
    "    # 2) Transcribe + align whole file\n",
    "    words = transcribe_with_alignment(std_mix_path, asr_model=ASR_MODEL, role=None)\n",
    "\n", 
    "    # 3) Diarize into speakers (pyannote)\n",
    "    diarized_turns = diarize_mixed(std_mix_path, words)\n",
    "\n",
    "    # 4) Write merged artifacts\n",
    "    write_timestamped_txt(diarized_turns, out_paths[\"merged\"] / \"transcript.timestamped.txt\")\n",
    "    write_plain_txt(diarized_turns,       out_paths[\"merged\"] / \"transcript.txt\")\n",
    "    srt_path = out_paths[\"merged\"] / \"subtitles.srt\"\n",
    "    write_srt(diarized_turns, srt_path)\n",
    "    if WRITE_VTT:\n",
    "        write_vtt(diarized_turns, out_paths[\"merged\"] / \"subtitles.vtt\")\n",
    "    if RENDER_BLACK:\n",
    "        render_black_video(srt_path, out_paths[\"merged\"] / \"black_subtitled.mp4\", audio_path=std_mix_path)\n",
    "\n",
    "    print(\"Combined (mixed) processing complete.\")\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "metadata": { "tags": ["summary"] },
   "source": [
    "# === Summary ===\n",
    "from pathlib import Path\n",
    "print(\"Artifacts in:\", out_paths[\"root\"]) \n",
    "for p in sorted(Path(out_paths[\"root\"]).rglob(\"*\")):\n",
    "    if p.is_file():\n",
    "        print(\" -\", p.relative_to(out_paths[\"root\"]))\n"
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": { "display_name": "Python 3", "language": "python", "name": "python3" },
  "language_info": { "name": "python", "version": "3.12" }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

